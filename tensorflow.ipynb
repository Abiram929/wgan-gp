{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader.\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from ops import *\n",
    "#from tensorflow.data.experimental import shuffle_and_repeat, map_and_batch\n",
    "from tensorflow.data import Dataset\n",
    "class ImageData(object):\n",
    "\n",
    "    \"\"\" Dataloader for loading images. \"\"\"\n",
    "\n",
    "    def __init__(self, load_size, channels, data_path, ids):\n",
    "\n",
    "        \"\"\" Init.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        load_size: int, input image size.\n",
    "        channels: int, number of channels.\n",
    "        data_path: str, path of input images.\n",
    "        ids: int, train/test split point.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.load_size = load_size\n",
    "        self.channels = channels\n",
    "        self.ids = ids\n",
    "\n",
    "        self.data_path = data_path\n",
    "        file_names = [f for f in os.listdir(data_path)\n",
    "                      if f.endswith('.jpg')]\n",
    "        self.file_dict = dict()\n",
    "        for f_name in file_names:\n",
    "            # key = f_name.split('.')[0].split('_')[0]\n",
    "            # side = f_name.split('.')[0].split('_')[-1]\n",
    "            # key = key + '_' + side\n",
    "            fields = f_name.split('.')[0].split('_')\n",
    "            identity = fields[0]\n",
    "            head_pose = fields[2]\n",
    "            side = fields[-1]\n",
    "            key = '_'.join([identity, head_pose, side])\n",
    "            if key not in self.file_dict.keys():\n",
    "                self.file_dict[key] = []\n",
    "                self.file_dict[key].append(f_name)\n",
    "            else:\n",
    "                self.file_dict[key].append(f_name)\n",
    "\n",
    "        self.train_images = []\n",
    "        self.train_angles_r = []\n",
    "        self.train_labels = []\n",
    "        self.train_images_t = []\n",
    "        self.train_angles_g = []\n",
    "\n",
    "        self.test_images = []\n",
    "        self.test_angles_r = []\n",
    "        self.test_labels = []\n",
    "        self.test_images_t = []\n",
    "        self.test_angles_g = []\n",
    "\n",
    "    def image_processing(\n",
    "        self,\n",
    "        filename,\n",
    "        angles_r,\n",
    "        labels,\n",
    "        filename_t,\n",
    "        angles_g\n",
    "    ):\n",
    "    # def image_processing(self,input):\n",
    "    #     print(type(input))\n",
    "    #     return input\n",
    "        \"\"\" Process input images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str, path of input image.\n",
    "        angles_r: list, gaze direction of input image.\n",
    "        labels: int, subject id. (deprecated!)\n",
    "        filename_t: str, path of target image.\n",
    "        angles_g: list, gaze direction of target image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image: tensor, float32, normalized input image.\n",
    "        angles_r: angels_r.\n",
    "        labels: labels.\n",
    "        image_t: tensor, float32, normalized target image.\n",
    "        angles_g: angles_g.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def _to_image(file_name):\n",
    "\n",
    "            \"\"\" Load image, normalize it and convert it into tf.tensor.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            file_name: str, image path.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            img: tf.tensor, tf.float32. Image tensor.\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            x = tf.io.read_file(file_name)\n",
    "            #img = tf.image.decode_jpeg(x, channels=self.channels)\n",
    "            img = tf.io.decode_jpeg(x, channels=self.channels)\n",
    "            img = tf.image.resize(img, [self.load_size, self.load_size])\n",
    "            #img = tf.image.resize_images(img, [self.load_size, self.load_size])\n",
    "           \n",
    "            img = tf.cast(img, tf.float32) / 127.5 - 1.0\n",
    "\n",
    "            return img\n",
    "\n",
    "        image = _to_image(filename)\n",
    "        image_t = _to_image(filename_t)\n",
    "\n",
    "        return image, angles_r, labels, image_t, angles_g\n",
    "\n",
    "    def preprocess(self):\n",
    "\n",
    "        for key in self.file_dict.keys():\n",
    "\n",
    "            if len(self.file_dict[key]) == 1:\n",
    "                continue\n",
    "\n",
    "            idx = int(key.split('_')[0])\n",
    "            flip = 1\n",
    "            if key.split('_')[-1] == 'R':\n",
    "                flip = -1\n",
    "\n",
    "            for f_r in self.file_dict[key]:\n",
    "\n",
    "                file_path = os.path.join(self.data_path, f_r)\n",
    "\n",
    "                h_angle_r = flip * float(\n",
    "                    f_r.split('_')[-2].split('H')[0]) / 15.0\n",
    "                    \n",
    "                v_angle_r = float(\n",
    "                    f_r.split('_')[-3].split('V')[0]) / 10.0\n",
    "                    \n",
    "\n",
    "                for f_g in self.file_dict[key]:\n",
    "\n",
    "                    file_path_t = os.path.join(self.data_path, f_g)\n",
    "\n",
    "                    h_angle_g = flip * float(\n",
    "                        f_g.split('_')[-2].split('H')[0]) / 15.0\n",
    "                        \n",
    "                    v_angle_g = float(\n",
    "                        f_g.split('_')[-3].split('V')[0]) / 10.0\n",
    "                        \n",
    "\n",
    "                    if idx <= self.ids:\n",
    "                        self.train_images.append(file_path)\n",
    "                        self.train_angles_r.append([h_angle_r, v_angle_r])\n",
    "                        self.train_labels.append(idx - 1)\n",
    "                        self.train_images_t.append(file_path_t)\n",
    "                        self.train_angles_g.append([h_angle_g, v_angle_g])\n",
    "                    else:\n",
    "                        self.test_images.append(file_path)\n",
    "                        self.test_angles_r.append([h_angle_r, v_angle_r])\n",
    "                        self.test_labels.append(idx - 1)\n",
    "                        self.test_images_t.append(file_path_t)\n",
    "                        self.test_angles_g.append([h_angle_g, v_angle_g])\n",
    "\n",
    "        print('\\nFinished preprocessing the dataset...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader():\n",
    "        \"\"\" load traing and testing dataset \"\"\"\n",
    "\n",
    "       \n",
    "\n",
    "        image_data_class = ImageData(load_size=64,\n",
    "                                     channels=3,\n",
    "                                     data_path='/home/user/Downloads/dataset/0P',\n",
    "                                     ids=50)\n",
    "        image_data_class.preprocess()\n",
    "\n",
    "        train_dataset_num = len(image_data_class.train_images)\n",
    "        test_dataset_num = len(image_data_class.test_images)\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (image_data_class.train_images,\n",
    "             image_data_class.train_angles_r,\n",
    "             image_data_class.train_labels,\n",
    "             image_data_class.train_images_t,\n",
    "             image_data_class.train_angles_g))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (image_data_class.test_images,\n",
    "             image_data_class.test_angles_r,\n",
    "             image_data_class.test_labels,\n",
    "             image_data_class.test_images_t,\n",
    "             image_data_class.test_angles_g))\n",
    "\n",
    "        # train_dataset = train_dataset.apply(\n",
    "        #     shuffle_and_repeat(train_dataset_num)).apply(\n",
    "        #     map_and_batch(image_data_class.image_processing,\n",
    "        #                   hps.batch_size,\n",
    "        #                   num_parallel_batches=8))\n",
    "        train_dataset =train_dataset.map(image_data_class.image_processing)\n",
    "        train_dataset.shuffle(32)\n",
    "        train_dataset = train_dataset.batch(4)\n",
    "       \n",
    "\n",
    "        return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator( x_init, reuse=False):\n",
    "\n",
    "    \"\"\" Discriminator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict.\n",
    "    x_init: input tensor.\n",
    "    reuse: bool, reuse the net if True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_gan: tensor, outputs for adversarial training.\n",
    "    x_reg: tensor, outputs for gaze estimation.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    layers = 5\n",
    "    channel = 64\n",
    "    image_size = 64\n",
    "\n",
    "    with tf.compat.v1.variable_scope('discriminator', reuse=reuse):\n",
    "\n",
    "        # 64 3 -> 32 64 -> 16 128 -> 8 256 -> 4 512 -> 2 1024\n",
    "\n",
    "        x = conv2d(x_init, channel, conv_filters_dim=4, d_h=2, d_w=2,\n",
    "                   scope='conv_0', pad=1, use_bias=True)\n",
    "        x = lrelu(x)\n",
    "\n",
    "        for i in range(1, layers):\n",
    "            x = conv2d(x, channel * 2, conv_filters_dim=4, d_h=2, d_w=2,\n",
    "                       scope='conv_%d' % i, pad=1, use_bias=True)\n",
    "            x = lrelu(x)\n",
    "            channel = channel * 2\n",
    "\n",
    "        filter_size = int(image_size / 2 ** layers)\n",
    "\n",
    "        x_gan = conv2d(x, 1, conv_filters_dim=filter_size, d_h=1, d_w=1,\n",
    "                       pad=1, scope='conv_logit_gan', use_bias=False)\n",
    "\n",
    "        x_reg = conv2d(x, 2, conv_filters_dim=filter_size, d_h=1, d_w=1,\n",
    "                       pad=0, scope='conv_logit_reg', use_bias=False)\n",
    "        x_reg = tf.reshape(x_reg, [-1, 2])\n",
    "\n",
    "        return x_gan, x_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr=data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generator(input_, angles, reuse=False):\n",
    "\n",
    "    \"\"\" Generator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_: tensor, input images.\n",
    "    angles: tensor, target gaze direction.\n",
    "    reuse: bool, reuse the net if True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x: tensor, generated image.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    channel = 64\n",
    "    style_dim = angles.get_shape().as_list()[-1]\n",
    "    #style_dim = angles.get_shape().as_list()[-1]\n",
    "\n",
    "    angles_reshaped = tf.reshape(angles, [-1, 1, 1, style_dim])\n",
    "    angles_tiled = tf.tile(angles_reshaped, [1, tf.shape(input_)[1],\n",
    "                                             tf.shape(input_)[2], 1])\n",
    "    x = tf.concat([input_, angles_tiled], axis=3)\n",
    "\n",
    "    with tf.compat.v1.variable_scope('generator', reuse=reuse):\n",
    "\n",
    "        # input layer\n",
    "        x = conv2d(x, channel, d_h=1, d_w=1, scope='conv2d_input',\n",
    "                   use_bias=False, pad=3, conv_filters_dim=7)\n",
    "        #x = instance_norm(x, scope='in_input')\n",
    "        #tf.keras.layers.BatchNormalization(axis=[0,1],epsilon=1e-05, center=True, scale=True)(x)\n",
    "        with tf.compat.v1.variable_scope('in_input'):\n",
    "            x=tf.keras.layers.BatchNormalization()(x)\n",
    "        x = relu(x)\n",
    "\n",
    "        # encoder\n",
    "        for i in range(2):\n",
    "\n",
    "            x = conv2d(x, 2 * channel, d_h=2, d_w=2, scope='conv2d_%d' % i,\n",
    "                       use_bias=False, pad=1, conv_filters_dim=4)\n",
    "            #x = instance_norm(x, scope='in_conv_%d' % i)\n",
    "            #tf.keras.layers.BatchNormalization(axis=[0,1],epsilon=1e-05, center=True, scale=True)(x)\n",
    "            with tf.compat.v1.variable_scope('in_conv_%d' % i):\n",
    "                x=tf.keras.layers.BatchNormalization()(x)\n",
    "            x = relu(x)\n",
    "            channel = 2 * channel\n",
    "\n",
    "        # bottleneck\n",
    "        for i in range(6):\n",
    "\n",
    "            x_a = conv2d(x, channel, conv_filters_dim=3, d_h=1, d_w=1,\n",
    "                         pad=1, use_bias=False, scope='conv_res_a_%d' % i)\n",
    "            #x_a = instance_norm(x_a, 'in_res_a_%d' % i)\n",
    "            with tf.compat.v1.variable_scope('in_res_a_%d' % i):\n",
    "                x_a=tf.keras.layers.BatchNormalization()(x_a)\n",
    "            x_a = relu(x_a)\n",
    "            x_b = conv2d(x_a, channel, conv_filters_dim=3, d_h=1, d_w=1,\n",
    "                         pad=1, use_bias=False, scope='conv_res_b_%d' % i)\n",
    "            #x_b = instance_norm(x_b, 'in_res_b_%d' % i)\n",
    "            with tf.compat.v1.variable_scope('in_res_b_%d' % i):\n",
    "                x_b=tf.keras.layers.BatchNormalization()(x_b)\n",
    "\n",
    "            x = x + x_b\n",
    "\n",
    "        # decoder\n",
    "        for i in range(2):\n",
    "\n",
    "            x = deconv2d(x, int(channel / 2), conv_filters_dim=4, d_h=2, d_w=2,\n",
    "                         use_bias=False, scope='deconv_%d' % i)\n",
    "            #x = instance_norm(x, scope='in_decon_%d' % i)\n",
    "            with tf.compat.v1.variable_scope('in_decon_%d' % i):\n",
    "                x=tf.keras.layers.BatchNormalization()(x)\n",
    "            x = relu(x)\n",
    "            channel = int(channel / 2)\n",
    "\n",
    "        x = conv2d(x, 3, conv_filters_dim=7, d_h=1, d_w=1, pad=3,\n",
    "                   use_bias=False, scope='output')\n",
    "        x = tanh(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all=next(itr)\n",
    "#output=discriminator(all[0])\n",
    "#output=generator(all[0],all[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/wgan-gp/ops.py:71: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv = tf.compat.v1.layers.conv2d(\n",
      "/home/user/wgan-gp/ops.py:107: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "  deconv = tf.compat.v1.layers.conv2d_transpose(\n"
     ]
    }
   ],
   "source": [
    "for t in data:\n",
    "    output=generator(t[0],t[1])\n",
    "    print(type(t[1]))\n",
    "    input_,angles=t[0],t[1]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64, 64, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[0].shape,output[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(output[0][0]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dim = angles.get_shape().as_list()[-1]\n",
    "\n",
    "angles_reshaped = tf.reshape(angles, [-1, 1, 1, style_dim])\n",
    "angles_tiled = tf.tile(angles_reshaped, [1, tf.shape(input_)[1],\n",
    "                                             tf.shape(input_)[2], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) (4, 1, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(angles.shape,angles_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64, 64, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64, 64, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.concat([input_, angles_tiled], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64, 64, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
